{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AE1</th>\n",
       "      <th>AE2</th>\n",
       "      <th>AE3</th>\n",
       "      <th>AE4</th>\n",
       "      <th>AE5</th>\n",
       "      <th>AE6</th>\n",
       "      <th>AE7</th>\n",
       "      <th>AE8</th>\n",
       "      <th>AE9</th>\n",
       "      <th>AE10</th>\n",
       "      <th>...</th>\n",
       "      <th>PE2</th>\n",
       "      <th>PE3</th>\n",
       "      <th>PE4</th>\n",
       "      <th>PE5</th>\n",
       "      <th>PE6</th>\n",
       "      <th>PE7</th>\n",
       "      <th>PE8</th>\n",
       "      <th>PE9</th>\n",
       "      <th>PE10</th>\n",
       "      <th>Parenting_style</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Authoration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Authorative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Authorative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Permissive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Permissive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AE1  AE2  AE3  AE4  AE5  AE6  AE7  AE8  AE9  AE10  ...  PE2  PE3  PE4  \\\n",
       "NO                                                     ...                  \n",
       "1     1    5    2    5    1    4    1    4    1     5  ...    4    3    1   \n",
       "2     1    4    2    4    2    5    1    4    5     5  ...    2    3    2   \n",
       "3     2    4    4    5    5    4    2    5    5     5  ...    4    3    4   \n",
       "4     1    3    2    4    2    4    1    3    2     5  ...    5    2    4   \n",
       "5     1    1    3    3    1    1    1    5    3     3  ...    5    1    4   \n",
       "\n",
       "    PE5  PE6  PE7  PE8  PE9  PE10  Parenting_style  \n",
       "NO                                                  \n",
       "1     4    1    2    4    1     1      Authoration  \n",
       "2     3    4    3    2    2     1      Authorative  \n",
       "3     4    4    4    4    3     3      Authorative  \n",
       "4     3    3    3    5    5     4       Permissive  \n",
       "5     3    4    3    4    4     3       Permissive  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/parenting_dataset_asli.csv\", index_col=\"NO\")\n",
    "data.drop(columns=[\"Responden\"], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input  features: (500, 52)\n",
      "Shape of Output features: (500,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['Parenting_style'], axis = 1)\n",
    "Y = data['Parenting_style']\n",
    "\n",
    "print(\"Shape of Input  features: {}\".format(X.shape))\n",
    "print(\"Shape of Output features: {}\".format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Authorative    182\n",
       "Authoration    163\n",
       "Permissive     155\n",
       "Name: Parenting_style, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AE1</th>\n",
       "      <th>AE2</th>\n",
       "      <th>AE3</th>\n",
       "      <th>AE4</th>\n",
       "      <th>AE5</th>\n",
       "      <th>AE6</th>\n",
       "      <th>AE7</th>\n",
       "      <th>AE8</th>\n",
       "      <th>AE9</th>\n",
       "      <th>AE10</th>\n",
       "      <th>...</th>\n",
       "      <th>PE1</th>\n",
       "      <th>PE2</th>\n",
       "      <th>PE3</th>\n",
       "      <th>PE4</th>\n",
       "      <th>PE5</th>\n",
       "      <th>PE6</th>\n",
       "      <th>PE7</th>\n",
       "      <th>PE8</th>\n",
       "      <th>PE9</th>\n",
       "      <th>PE10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AE1  AE2  AE3  AE4  AE5  AE6  AE7  AE8  AE9  AE10  ...  PE1  PE2  PE3  \\\n",
       "NO                                                     ...                  \n",
       "1     1    5    2    5    1    4    1    4    1     5  ...    1    4    3   \n",
       "2     1    4    2    4    2    5    1    4    5     5  ...    1    2    3   \n",
       "3     2    4    4    5    5    4    2    5    5     5  ...    4    4    3   \n",
       "4     1    3    2    4    2    4    1    3    2     5  ...    5    5    2   \n",
       "5     1    1    3    3    1    1    1    5    3     3  ...    2    5    1   \n",
       "\n",
       "    PE4  PE5  PE6  PE7  PE8  PE9  PE10  \n",
       "NO                                      \n",
       "1     1    4    1    2    4    1     1  \n",
       "2     2    3    4    3    2    2     1  \n",
       "3     4    4    4    4    4    3     3  \n",
       "4     4    3    3    3    5    5     4  \n",
       "5     4    3    4    3    4    4     3  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Therefore, our final shape of output feature will be (500, 3)\n"
     ]
    }
   ],
   "source": [
    "lbl_clf = LabelEncoder()\n",
    "Y_encoded = lbl_clf.fit_transform(Y)\n",
    "\n",
    "#Keras requires your output feature to be one-hot encoded values.\n",
    "Y_final = tf.keras.utils.to_categorical(Y_encoded)\n",
    "\n",
    "print(\"Therefore, our final shape of output feature will be {}\".format(Y_final.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Input shape\t: (400, 52)\n",
      "Testing Input shape\t: (100, 52)\n",
      "Training Output shape\t: (400, 3)\n",
      "Testing Output shape\t: (100, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_final, test_size=0.2, random_state=seed, stratify=Y_encoded, shuffle=True)\n",
    "\n",
    "print(\"Training Input shape\\t: {}\".format(x_train.shape))\n",
    "print(\"Testing Input shape\\t: {}\".format(x_test.shape))\n",
    "print(\"Training Output shape\\t: {}\".format(y_train.shape))\n",
    "print(\"Testing Output shape\\t: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_clf = StandardScaler()\n",
    "x_train_new = std_clf.fit_transform(x_train)\n",
    "x_test_new = std_clf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 1.2363 - accuracy: 0.3575\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 1.0241 - accuracy: 0.4975\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 0.9201 - accuracy: 0.5625\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 0.8242 - accuracy: 0.6025\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.7487 - accuracy: 0.6300\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 0.6903 - accuracy: 0.6475\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 0.6463 - accuracy: 0.6550\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 0.6100 - accuracy: 0.6900\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 0.5767 - accuracy: 0.7200\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.5438 - accuracy: 0.7300\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 0.5179 - accuracy: 0.7425\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 0.4906 - accuracy: 0.7575\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 0.4695 - accuracy: 0.7850\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 0.4459 - accuracy: 0.8025\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 0.4246 - accuracy: 0.8125\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 0.4033 - accuracy: 0.8250\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 0.3836 - accuracy: 0.8375\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.3579 - accuracy: 0.8500\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 0.3315 - accuracy: 0.8625\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 0.2988 - accuracy: 0.8975\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 0.2735 - accuracy: 0.9200\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 838us/step - loss: 0.2424 - accuracy: 0.9275\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 950us/step - loss: 0.2104 - accuracy: 0.9425\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 0.1819 - accuracy: 0.9475\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.1591 - accuracy: 0.9625\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 0.1404 - accuracy: 0.9600\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.1211 - accuracy: 0.9725\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 825us/step - loss: 0.1056 - accuracy: 0.9800\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 0.0938 - accuracy: 0.9775\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.0819 - accuracy: 0.9850\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 0.0720 - accuracy: 0.9850\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 0.0626 - accuracy: 0.9875\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.0528 - accuracy: 0.9900\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 0.0442 - accuracy: 0.9975\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 0.0388 - accuracy: 0.9975\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 0.0338 - accuracy: 0.9975\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 0.0323 - accuracy: 0.9975\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 0.0240 - accuracy: 0.9975\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 875us/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 813us/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 813us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 813us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 688us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 913us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 863us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 838us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 875us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 838us/step - loss: 9.3100e-04 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 8.6380e-04 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 8.0084e-04 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 813us/step - loss: 7.4672e-04 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 7.0068e-04 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 900us/step - loss: 6.5090e-04 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 6.1539e-04 - accuracy: 1.0000\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 913us/step - loss: 5.7763e-04 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 950us/step - loss: 5.4306e-04 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 925us/step - loss: 5.0716e-04 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 4.7627e-04 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 925us/step - loss: 4.4949e-04 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 925us/step - loss: 4.2682e-04 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 975us/step - loss: 4.0188e-04 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 981us/step - loss: 3.8004e-04 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 938us/step - loss: 3.5896e-04 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 3.3820e-04 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 825us/step - loss: 3.1939e-04 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 3.0222e-04 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 2.8580e-04 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 2.6956e-04 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 2.5698e-04 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 2.4024e-04 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 2.2719e-04 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 2.1426e-04 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 2.0367e-04 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 1.9071e-04 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 1.7973e-04 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 1.6847e-04 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 863us/step - loss: 1.5931e-04 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 825us/step - loss: 1.5263e-04 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 838us/step - loss: 1.4462e-04 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 838us/step - loss: 1.3609e-04 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 863us/step - loss: 1.2851e-04 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 863us/step - loss: 1.2131e-04 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 838us/step - loss: 1.1576e-04 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 865us/step - loss: 1.0871e-04 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 838us/step - loss: 1.0298e-04 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 9.7286e-05 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 722us/step - loss: 9.2189e-05 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 8.8616e-05 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 8.3516e-05 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 7.9373e-05 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 7.4681e-05 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 7.0858e-05 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 6.7176e-05 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 6.3959e-05 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 6.0803e-05 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 825us/step - loss: 5.7895e-05 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 825us/step - loss: 5.4718e-05 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 5.2171e-05 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 4.9590e-05 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 4.7173e-05 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 4.4744e-05 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 4.2748e-05 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 4.0409e-05 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 3.8525e-05 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 3.6822e-05 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 813us/step - loss: 3.4872e-05 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 3.3229e-05 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 3.1607e-05 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 2.9903e-05 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 2.8446e-05 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 2.7248e-05 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 813us/step - loss: 2.6009e-05 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 888us/step - loss: 2.4552e-05 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 838us/step - loss: 2.3439e-05 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 850us/step - loss: 2.2241e-05 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 875us/step - loss: 2.1158e-05 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 813us/step - loss: 2.0233e-05 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 813us/step - loss: 1.9290e-05 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 1.8320e-05 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 1.7457e-05 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 1.6611e-05 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 1.5778e-05 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 1.5137e-05 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 825us/step - loss: 1.4367e-05 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 1.3673e-05 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 1.3021e-05 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 1.2376e-05 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 788us/step - loss: 1.1790e-05 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 825us/step - loss: 1.1127e-05 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 813us/step - loss: 1.0586e-05 - accuracy: 1.0000\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 850us/step - loss: 1.0044e-05 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 9.5117e-06 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 9.0277e-06 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 8.6618e-06 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 8.1605e-06 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 7.7991e-06 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 7.4513e-06 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 7.1059e-06 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 6.7587e-06 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 6.4178e-06 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 775us/step - loss: 6.1177e-06 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 5.8197e-06 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 5.5637e-06 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 5.2898e-06 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 763us/step - loss: 5.0678e-06 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 4.8124e-06 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 4.5835e-06 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 4.3696e-06 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 4.1624e-06 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 988us/step - loss: 3.9803e-06 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 3.8209e-06 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 3.6439e-06 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 3.4472e-06 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 3.3033e-06 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 800us/step - loss: 3.1358e-06 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 3.0145e-06 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 2.8464e-06 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 2.7320e-06 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 2.6023e-06 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.4715e-06 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.3639e-06 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 2.2566e-06 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 750us/step - loss: 2.1416e-06 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 2.0441e-06 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 1.9586e-06 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 1.8650e-06 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 1.7846e-06 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 725us/step - loss: 1.7053e-06 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 1.6197e-06 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 1.5509e-06 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 1.4836e-06 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 738us/step - loss: 1.4135e-06 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 700us/step - loss: 1.3462e-06 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 713us/step - loss: 1.2875e-06 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(16, input_dim=52, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_history = model.fit(x_train_new, y_train, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1000us/step - loss: 3.5840 - accuracy: 0.7400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.584010124206543, 0.7400000095367432]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_new, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 16)                848       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 1,083\n",
      "Trainable params: 1,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Use the tf.saved_model API to save your model in the SavedModel format. \n",
    "export_dir = 'saved_model/1'\n",
    "\n",
    "tf.saved_model.save(model, export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select mode of optimization\n",
    "mode = \"Speed\" \n",
    "\n",
    "if mode == 'Storage':\n",
    "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE\n",
    "elif mode == 'Speed':\n",
    "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
    "else:\n",
    "    optimization = tf.lite.Optimize.DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Use the TFLiteConverter SavedModel API to initialize the converter\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "\n",
    "# Set the optimzations\n",
    "converter.optimizations = [optimization]\n",
    "\n",
    "# Invoke the converter to finally generate the TFLite model\n",
    "tflite_model = tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_file = pathlib.Path('./model.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-71e91bef2057>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# summarize history for accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model_history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
